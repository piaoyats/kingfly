分布式的BulkLoading

0 采用HFileOutputFormat执行job最后会在output目录下生成
  ---文件夹 named 列族名
     --- 每个partition对应的文件（命名形如： 0ee28b6f4b7f4f26b58892b0b434b75c）
		
1 hbase项目用了很多公共buffer 减少gc压力，这也带来另一个问题，必须要copy下否则会拿到相同值。
  --- 这里需要明确的是，在什么情况下会出现这种问题。形如：	
    val bytesUtils = BytesUtils.create(IntegerType)  
    val splitKeys = (1 to 40).filter(_ % 5 == 0).map { r =>
      new ImmutableBytesWritableWrapper(bytesUtils.toBytes(r))
    }
	println(splitKeys(0))
	会出现这种情况！

2 
  2.1 每个partition存为Hfile
  方案1： 如果修改 writeshard 添加：
  val output = config.get("mapred.output.dir")
  config.set("mapred.output.dir", output + Random.nextInt(1000))
  则会生成随机的output目录，形如：
  hfileoutput3
  --- _temporary
  --- 0
     --- _temporary
	 --- task_201412231942_r_000004
	    --- cf
		   --- 0ee28b6f4b7f4f26b58892b0b434b75c
  
  无法保证输出目录的有效性。
  
  
  2.2 每个partition里面调用 bulk loading 工具
