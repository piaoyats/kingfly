kf@kf:/home/wf/code/spark3$ ll pair.orc/
total 28
drwxrwxr-x  2 kf kf 4096 Oct  3 22:49 ./
drwxrwxr-x 34 kf kf 4096 Oct  3 22:49 ../
-rwxrwxrwx  1 kf kf  334 Oct  3 22:49 part-r-1.orc*
-rw-rw-r--  1 kf kf   12 Oct  3 22:49 .part-r-1.orc.crc
-rwxrwxrwx  1 kf kf  339 Oct  3 22:49 part-r-2.orc*
-rw-rw-r--  1 kf kf   12 Oct  3 22:49 .part-r-2.orc.crc
-rwxrwxrwx  1 kf kf    0 Oct  3 22:49 _SUCCESS*
-rw-rw-r--  1 kf kf    8 Oct  3 22:49 ._SUCCESS.crc
kf@kf:/home/wf/code/spark3$ ll pair.parquet/
total 36
drwxrwxr-x  2 kf kf 4096 Oct  3 22:49 ./
drwxrwxr-x 34 kf kf 4096 Oct  3 22:49 ../
-rwxrwxrwx  1 kf kf  440 Oct  3 22:49 _metadata*
-rw-rw-r--  1 kf kf   12 Oct  3 22:49 ._metadata.crc
-rwxrwxrwx  1 kf kf  752 Oct  3 22:49 part-r-1.parquet*
-rw-rw-r--  1 kf kf   16 Oct  3 22:49 .part-r-1.parquet.crc
-rwxrwxrwx  1 kf kf  753 Oct  3 22:49 part-r-2.parquet*
-rw-rw-r--  1 kf kf   16 Oct  3 22:49 .part-r-2.parquet.crc
-rwxrwxrwx  1 kf kf    0 Oct  3 22:49 _SUCCESS*
-rw-rw-r--  1 kf kf    8 Oct  3 22:49 ._SUCCESS.crc

貌似orc的压缩效果更好！

orc 对接 datasource api:
这里的疑问是
1 在HiveContext 下 rdd.registerTempTable("records") 是注册到HiveMetastoreCatalog吗，但HiveMetastoreCatalog里面的registerTable都没有实现，这是怎么回事？
  还有就是 HiveMetastoreCatalog 的 lookupRelation里面是到hive的元数据库获取table，那也就是说注册的临时表不是在这里获取的。 总结起来就是
  HiveContext 下 rdd.registerTempTable("records") 注册到哪去了，又是谁去哪拿的？
  答： HiveMetastoreCatalog里面的registerTable都没有实现，实际调用时用的是父辈OverrideCatalog的方法;读的时候奇怪了，也是到父类OverrideCatalog的方法中lookup的
  这有可能是 scala的特有语法 abstract override def，确实是的 http://stackoverflow.com/questions/2038370/traits-and-abstract-methods-override-in-scala


2 为什么把 discoverPartitions 提出去，就会有序列化问题

3 既然以后都要统一到sqlcontext 来，那现在集成到hivecontext 有意义吗？

4 跑个测试用例都报oom问题？难道是有内存泄漏？
Exception in thread "SparkListenerBus" 
Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "SparkListenerBus"

-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m
